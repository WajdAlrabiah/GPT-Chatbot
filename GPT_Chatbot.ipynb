{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBpD4wQ2De5q"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot:\n",
        "    def __init__(self, model_name='gpt2'):\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    def validate_input(self, text):\n",
        "        # Remove any non-alphanumeric characters or symbols\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "        # Limit input length to 100 characters\n",
        "        text = text[:200] #text[:200]\n",
        "        return text\n",
        "\n",
        "    def tokenize_input(self, text):\n",
        "        inputs = self.tokenizer.encode(text, return_tensors='pt')\n",
        "        return inputs\n",
        "\n",
        "    def prepare_data(self, conversations):\n",
        "        inputs = [self.tokenize_input(conversation) for conversation in conversations]\n",
        "        return torch.cat(inputs, dim=1)\n",
        "\n",
        "    def train_model(self, input_data):\n",
        "        # Fine-tune the model with input data (not implemented in this example)\n",
        "        pass\n",
        "\n",
        "    def generate_response(self, input_text, max_length=50):\n",
        "        input_text = self.validate_input(input_text)\n",
        "        input_ids = self.tokenize_input(input_text)\n",
        "        with torch.no_grad():\n",
        "            output = self.model.generate(input_ids,\n",
        "                                         max_length=max_length,\n",
        "                                         num_return_sequences=1)\n",
        "        response = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        response = {\"response\": response}\n",
        "        return response"
      ],
      "metadata": {
        "id": "ZsF32lIpECkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    chatbot = Chatbot()\n",
        "\n",
        "    # Example conversation data\n",
        "    conversations = [\n",
        "        \"User: Hello! How are you?\\nBot: Im doing well thank you How about you\",\n",
        "        \"User: Can you help me with a question?\\nBot: Of course What do you need help with\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    input_data = chatbot.prepare_data(conversations)\n",
        "\n",
        "    # Train model (not implemented in this example)\n",
        "    chatbot.train_model(input_data)\n",
        "\n",
        "    # Generate response\n",
        "    user_input = \"User Hi what's your name Bot\"\n",
        "    response = chatbot.generate_response(user_input)\n",
        "    print(\"Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LV9ydYNEGQ1",
        "outputId": "735b64df-d55a-470e-f3ff-965bbfd61152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: {'response': 'User Hi whats your name Botany?\\n\\nBotany is a botany language that is used to describe the behavior of plants and animals. It is used to describe the behavior of plants and animals.\\n\\nBotany is a language that is'}\n"
          ]
        }
      ]
    }
  ]
}